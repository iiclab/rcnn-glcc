# This file is based on "Base-RCNN-C4.yaml" and "faster_rcnn_R_50_C4_3x.yaml"

MODEL:
  DEVICE: "cuda:0"
  META_ARCHITECTURE: "GeneralizedRCNN_GLCC"
  WEIGHTS: "./zoo/faster_rcnn_R_50_C4_3x_model_final_f97cb7.pkl"  # COCO Pre-trained
  PIXEL_MEAN: [41.369, 31.645, 29.044]  # Mean BGR in saba 2017 dataset
  PIXEL_STD: [6.3163, 4.930, 4.899]     # STD  BGR in saba 2017 dataset
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  RPN:
    PRE_NMS_TOPK_TEST: 6000
    POST_NMS_TOPK_TEST: 1000
  ROI_HEADS:
    NAME: "Res5ROIHeads_GLCC"
    BATCH_SIZE_PER_IMAGE: 128   # The "RoIHead batch size"
    NUM_CLASSES: 2  # Red and Fish

INPUT:
  MIN_SIZE_TRAIN: (1024,)
  MAX_SIZE_TRAIN: 1224
  MIN_SIZE_TEST: 1024
  MAX_SIZE_TEST: 1224

DATASETS:
  TRAIN: ("saba_2017_train",)
  TEST: ("saba_2017_test",)

DATALOADER:
  NUM_WORKERS: 2

SOLVER:
  IMS_PER_BATCH: 2  # This is the real "batch size" commonly known to deep learning people
  BASE_LR: 0.00025
  STEPS: (7000, 9000)  # No decay if [] 
  MAX_ITER: 10000
  CHECKPOINT_PERIOD: 5000

OUTPUT_DIR: "./output/base"
VERSION: 2
